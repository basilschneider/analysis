#!/usr/bin/env bash

# Wrapper script to create n-tuples from MiniAODs

set -e -o pipefail

dir=~/analysis/datasets/
out=output
nEvts=-1
nSplitEvts=50000
sample=TTJets_LO
condor=false
debug=false
dryrun=""

usage(){
    echo "Usage: $0 [option]"
    echo "where [option] can be"
    echo "-h                 Show this help"
    echo "-o output          Set name of output directory (default: $out)"
    echo "-d dir             Path to output directory (default: $dir)"
    echo "-n N               Process N events (default: $nEvts)"
    echo "-s sample          Run over sample (default: $sample)"
    echo "                   See samples for a list of samples"
    echo "                   Use \"all\" to run over all samples"
    echo "-c                 Run on condor (default: $condor)"
    echo "--debug            Debug messages (default: $debug)"
    echo "--dryrun           Don't send jobs"
}


parseOptions(){

    # Check for flags
    OPT=$(getopt \
        --options ho:d:n:s:c \
        --long debug \
        --long dryrun \
        --name "$0" \
        -- "$@"
    )

    eval set -- "${OPT}"

    while true; do
        case "${1}" in
            -h) usage
                exit 0;;
            -o) out="${2}"
                shift 2;;
            -d) dir="${2}"
                shift 2;;
            -n) nEvts="${2}"
                shift 2;;
            -s) sample="${2}"
                shift 2;;
            -c) condor=true
                shift 1;;
            --debug) debug=true
                shift 1;;
            --dryrun) dryrun="echo"
                shift 1;;
            --) shift
                break;;
        esac
    done

    # Check for positional arguments
    if [ $# -ne 0 ]; then
        usage
        exit 1
    fi

    # After parsing all options, set path's
    cfgfile=${CMSSW_BASE}/src/CMGTools/SUSYAnalysis/cfg/
    cfgfile+=run_susySingleLepton_v2_cfg.py
    eosout=/eos/uscms/store/user/bschneid/analysis/trees/"${out}"
    condorlogs="${out}"/logs/
}

produceTrees(){
    # Commands to be executed later
    cmd=()

    if [ "${condor}" == true ]; then
        cmdCondor
    else
        cmdLocal
    fi
}

cmdLocal(){
    # Report what you are doing
    cmd+=('echo Run locally, only over first file in sample.')
    cmd+=('echo This is used for testing and debugging.')

    # Modify config file
    cmd+=('sed -i "/sedAnchor03/s/comp = [^ ]*/comp = ${sample}/" ${cfgfile}')
    cmd+=('cd ${CMSSW_BASE}/src/CMGTools/SUSYAnalysis/cfg/')

    # Run
    cmd+=('${dryrun} heppy ${dir}/${out} run_susySingleLepton_v2_cfg.py -p 0 -f')
    # If the variable is set, run only over ${nEvts} events
    if [ ${nEvts} -ge 0 ]; then
        cmdadd '-N ${nEvts}'
    fi
}

cmdCondor(){
    # Get info about sample(s)
    cmd+=('echo Get info about requested sample')
    cmd+=('samplestr=$(awk "/\<${sample}\>/ { print \$2 }" samples)')

    # Check if sample was found
    cmd+=('if [[ -z ${samplestr} ]]; then echo Sample $sample not found.;')
    cmdadd 'echo Exit.; exit; fi'

    # Get number of files for sample
    cmd+=('noJobs=0')
    cmd+=('echo -n "Get number of files for ${sample}... "')
    cmd+=('chunks=$(das_client.py --query="summary dataset=${samplestr}"')
    cmdadd '--key /tmp/x509up_u${UID} --cert /tmp/x509up_u${UID}'
    cmdadd '| awk "/nfiles/ {print \$3}")'
    cmd+=('noJobs=$(( ${noJobs} + ${chunks} ))')
    cmd+=('echo $chunks')

    # Modify config file
    cmd+=('sed -i "/sedAnchor03/s/comp = [^ ]*/comp = ${sample}/" ${cfgfile}')

    # Create directory for condor logs
    cmd+=('mkdir -p ${condorlogs}')

    # Create output directory on eos (don't know how to do that on the worker
    # nodes)
    cmd+=('eos root://cmseos.fnal.gov/ mkdir -p ${eosout}')

    # Change output files of condor
    cmd+=('sed -i "s/^Output.*/Output =')
    cmdadd '${condorlogs//\//\\/}\/tree_production_\$(Cluster).stdout/"'
    cmdadd 'condor_trees_submission;'
    cmd+=('sed -i "s/^Error.*/Error =')
    cmdadd '${condorlogs//\//\\/}\/tree_production_\$(Cluster).stderr/"'
    cmdadd 'condor_trees_submission;'
    cmd+=('sed -i "s/^Log.*/Log =')
    cmdadd '${condorlogs//\//\\/}\/tree_production_\$(Cluster).condor/"'
    cmdadd 'condor_trees_submission;'

    # Pack directory for submission
    cmd+=('echo -n "Pack directories for submission... ";')
    cmd+=('rm -f tarball.tar.gz;')
    cmd+=('tar czf tarball.tar.gz -C ${CMSSW_BASE%/*}')
    cmdadd '--exclude .git ${CMSSW_BASE##*/};'
    cmd+=('rm -rf tarball_caf.tar.gz;')
    cmd+=('tar czf tarball_caf.tar.gz --transform "s/python/caf/"')
    cmdadd '-C /afs/cern.ch/cms/caf python;'
    cmd+=('tar czf tarball_cmgdataset.tar.gz -C ~/ .cmgdataset')
    cmdadd '|| (echo ~/.cmgdataset not found && exit 1);'
    cmd+=('echo Done.;')

    # Report number of jobs
    cmd+=('echo Will send ${noJobs} jobs to condor.;')

    # Copy condor submission template
    cmdadd 'rm -f condor_trees_submission_temp;'
    cmdadd 'cp condor_trees_submission{,_temp};'

    # Append output files to condor script
    cmdadd 'echo "Output ='
    cmdadd '${condorlogs}/tree_production_\$(Cluster).\$(Process).stdout"'
    cmdadd '>> condor_trees_submission_temp;'
    cmdadd 'echo "Error ='
    cmdadd '${condorlogs}/tree_production_\$(Cluster).\$(Process).stderr"'
    cmdadd '>> condor_trees_submission_temp;'
    cmdadd 'echo "Log ='
    cmdadd '${condorlogs}/tree_production_\$(Cluster).\$(Process).condor"'
    cmdadd '>> condor_trees_submission_temp;'

    # Loop over number of chunks
    cmd+=('for ((chunk=0; chunk<${chunks}; ++chunk)); do')

    # Append arguments to condor script
    cmdadd 'echo "Arguments = '
    cmdadd '${CMSSW_BASE##*/} ${CMSSW_BASE##*/}${cfgfile#*${CMSSW_BASE##*/}}'
    cmdadd '${eosout} ${nEvts} ${chunk}"'
    cmdadd '>> condor_trees_submission_temp;'
    cmdadd 'echo "Queue 1" >> condor_trees_submission_temp;'

    # End loop
    cmdadd 'done;'

    # To capture the job id but still print it to stdout, we need an additional
    # file descriptor, pointing to stdout
    cmdadd 'exec 3>&1;'

    # Send jobs, one for each chunk, tee output to stdout and to fd3
    cmdadd 'jobID=$(${dryrun} condor_submit condor_trees_submission_temp'
    cmdadd '| tee /dev/fd/3);'

    # Close fd3
    cmdadd 'exec 3>&-;'

    # Extract job ID
    cmdadd 'if [ -z "${dryrun}" ]; then'
    cmdadd 'jobID=$(grep -o "[0-9]\{4,\}" <<< "${jobID}");'
    cmdadd 'else jobID=999999; fi;'

    # Copy condor file to logs file, for later resubmission if needed
    cmdadd 'mv condor_trees_submission_temp'
    cmdadd '${condorlogs}/condor_trees_submission_${jobID};'

    # Report number of jobs again
    cmd+=('echo Sent ${noJobs} jobs to condor.;')
}

# Append to last cmd entry
cmdadd(){
    cmd[${#cmd[@]}-1]+=" $1"
}

# Invoke cmd command
invokeCmd(){
    # Invoke command(s) in subshell
    (
        for c in "${cmd[@]}"; do
            if [ "$debug" == true ]; then
                echo "$c"
            fi
            eval "$c"
        done
    )
}

main(){
    parseOptions "$@"
    produceTrees
    invokeCmd
}

main "$@"
