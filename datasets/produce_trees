#!/usr/bin/env bash

# Wrapper script to create n-tuples from MiniAODs

set -e -o pipefail

dir=~/analysis/datasets/
out=output
nEvts=-1
nSplitEvts=50000
sample=TTJets_LO
condor=false
chunk=false
hadd=false
dryrun=""

usage(){
    echo "Usage: $0 [option]"
    echo "where [option] can be"
    echo "-h                 Show this help"
    echo "-o output          Set name of output directory (default: $out)"
    echo "-d dir             Path to output directory (default: $dir)"
    echo "-n N               Process N events (default: $nEvts)"
    echo "-s sample          Run over sample (default: $sample)"
    echo "                   See samples for a list of samples"
    echo "                   Use \"all\" to run over all samples (on condor)"
    echo "-c                 Run on condor (default: $condor)"
    echo "--chunk            run only over first chunk (default: $chunk)"
    echo "--hadd             hadd files on eos (default: $hadd)"
    echo "--dryrun           Don't send jobs"
}


parseOptions(){

    # Check for flags
    OPT=$(getopt \
        --options ho:d:n:s:c \
        --long chunk \
        --long hadd \
        --long dryrun \
        --name "$0" \
        -- "$@"
    )

    eval set -- "${OPT}"

    while true; do
        case "${1}" in
            -h) usage
                exit 0;;
            -o) out="${2}"
                shift 2;;
            -d) dir="${2}"
                shift 2;;
            -n) nEvts="${2}"
                shift 2;;
            -s) sample="${2}"
                shift 2;;
            -c) condor=true
                shift 1;;
            --chunk) chunk=true
                shift 1;;
            --hadd) hadd=true
                shift 1;;
            --dryrun) dryrun="echo"
                shift 1;;
            --) shift
                break;;
        esac
    done

    # Check for positional arguments
    if [ $# -ne 0 ]; then
        usage
        exit 1
    fi

    # After parsing all options, set path's
    cfgfile=${CMSSW_BASE}/src/CMGTools/SUSYAnalysis/cfg/
    cfgfile+=run_susySingleLepton_v2_cfg.py
    eos=root://cmseos.fnal.gov/
    eosout=/eos/uscms/store/user/bschneid/analysis/trees/"${out}"
    eoschunk="${eosout}"/chunks
    condorlogs="${out}"/logs/
    outfiles="${out}"/outfiles.txt

    # Absolute path to log file
    if [ "${out:0:1}" != "/" ]; then
        log="${PWD}"/"${out}"/log.out
    else
        log="${out}"/log.out
    fi

    # Create directory for logs
    mkdir -p "${condorlogs}"
}

produceTrees(){
    # Commands to be executed later
    cmd=()

    if [ "${condor}" == true ]; then
        cmdCondor
    else
        cmdLocal
    fi
    invokeCmd
}

cmdLocal(){
    # Report what you are doing
    cmd+=('echo Run locally, only over first file in sample.')
    cmd+=('echo This is used for testing and debugging.')

    # Modify config file
    cmd+=('sed -i "/sedAnchor03/s/comp = [^ ]*/comp = ${sample}/" ${cfgfile}')
    cmd+=('cd ${CMSSW_BASE}/src/CMGTools/SUSYAnalysis/cfg/')

    # Run
    cmd+=('${dryrun} heppy ${dir}/${out} run_susySingleLepton_v2_cfg.py -p 0 -f')
    # If the variable is set, run only over ${nEvts} events
    if [ ${nEvts} -ge 0 ]; then
        cmdadd '-N ${nEvts}'
    fi
}

cmdCondor(){
    # Arrays with info about samples
    cmd+=('samples=()')
    cmd+=('samplesstr=()')
    cmd+=('chunks=()')
    cmd+=('noJobs=0')

    # Loop over samples file to get job information
    cmd+=('while read samplename samplestring; do')
    cmdadd 'if [ "${sample}" == "${samplename}" ] || [ "${sample}" == "all" ]; then'
    # Skip if first character in samples file is "#"
    cmdadd 'if [ "${samplename:0:1}" == "#" ]; then continue; fi;'
    cmdadd 'echo -n "Get number of files for ${samplename}... ";'
    cmdadd 'samples+=("${samplename}");'
    cmdadd 'samplesstr+=("${samplestring}");'
    cmdadd 'if [ "$chunk" == "true" ]; then chunks+=(1); else'
    cmdadd 'chunks+=($(das_client.py '
    cmdadd '--query="summary dataset=${samplestring}"'
    cmdadd '--key /tmp/x509up_u${UID} --cert /tmp/x509up_u${UID}'
    cmdadd '| awk "/nfiles/ {print \$3}")); fi;'
    cmdadd 'echo ${chunks[${#chunks[@]}-1]};'
    cmdadd 'noJobs=$(( $noJobs + ${chunks[${#chunks[@]}-1]} ));'
    cmdadd 'fi; done < samples;'

    # Check if sample was found
    cmd+=('if [[ "${#samples[@]}" -eq 0 ]]; then echo Sample $sample not found.;')
    cmdadd 'echo Exit.; exit; fi'

    # Change output files of condor
    cmd+=('sed -i "s/^Output.*/Output =')
    cmdadd '${condorlogs//\//\\/}\/tree_production_\$(Cluster).stdout/"'
    cmdadd 'condor_trees_submission;'
    cmd+=('sed -i "s/^Error.*/Error =')
    cmdadd '${condorlogs//\//\\/}\/tree_production_\$(Cluster).stderr/"'
    cmdadd 'condor_trees_submission;'
    cmd+=('sed -i "s/^Log.*/Log =')
    cmdadd '${condorlogs//\//\\/}\/tree_production_\$(Cluster).condor/"'
    cmdadd 'condor_trees_submission;'

    # Pack directory for submission
    cmd+=('echo -n "Pack directories for submission... ";')
    cmd+=('rm -f tarball.tar.gz;')
    cmd+=('tar czf tarball.tar.gz -C ${CMSSW_BASE%/*}')
    cmdadd '--exclude .git ${CMSSW_BASE##*/};'
    cmd+=('rm -rf tarball_caf.tar.gz;')
    cmd+=('tar czf tarball_caf.tar.gz --transform "s/python/caf/"')
    cmdadd '-C /afs/cern.ch/cms/caf python;'
    cmd+=('tar czf tarball_cmgdataset.tar.gz -C ~/ .cmgdataset')
    cmdadd '|| (echo ~/.cmgdataset not found && exit 1);'
    cmd+=('echo Done.;')

    # Report number of jobs
    cmd+=('echo Will send ${noJobs} jobs to condor.;')

    # Loop over requested samples (1 or all)
    cmd+=('for ((idx=0; idx<${#samples[@]}; ++idx)); do')

    # Copy condor submission template
    cmdadd 'rm -f condor_trees_submission_temp;'
    cmdadd 'cp condor_trees_submission{,_temp};'

    # Append output files to condor script
    cmdadd 'echo "Output ='
    cmdadd '${condorlogs}/tree_production_\$(Cluster).\$(Process).stdout"'
    cmdadd '>> condor_trees_submission_temp;'
    cmdadd 'echo "Error ='
    cmdadd '${condorlogs}/tree_production_\$(Cluster).\$(Process).stderr"'
    cmdadd '>> condor_trees_submission_temp;'
    cmdadd 'echo "Log ='
    cmdadd '${condorlogs}/tree_production_\$(Cluster).\$(Process).condor"'
    cmdadd '>> condor_trees_submission_temp;'

    # Loop over number of chunks
    cmdadd 'for ((chunk_idx=0; chunk_idx<${chunks[idx]}; ++chunk_idx)); do'

    # Write name of output directory to text file
    cmdadd 'echo "${samples[idx]}_${chunk_idx}" >> ${outfiles};'

    # Append arguments to condor script
    cmdadd 'echo "Arguments = '
    cmdadd '${CMSSW_BASE##*/} ${CMSSW_BASE##*/}${cfgfile#*${CMSSW_BASE##*/}}'
    cmdadd '${samples[idx]} ${eoschunk} ${nEvts} ${chunk_idx}"'
    cmdadd '>> condor_trees_submission_temp;'
    cmdadd 'echo "Queue 1" >> condor_trees_submission_temp;'

    # End loop
    cmdadd 'done;'

    # To capture the job id but still print it to stdout, we need an additional
    # file descriptor, pointing to stdout
    cmdadd 'exec 3>&1;'

    # Send jobs, one for each chunk, tee output to stdout and to fd3
    cmdadd 'jobID=$(${dryrun} condor_submit condor_trees_submission_temp'
    cmdadd '| tee /dev/fd/3);'

    # Close fd3
    cmdadd 'exec 3>&-;'

    # Extract job ID
    cmdadd 'if [ -z "${dryrun}" ]; then'
    cmdadd 'jobID=$(grep -o "[0-9]\{5,\}" <<< "${jobID}");'
    cmdadd 'else jobID=999999; fi;'

    # Copy condor file to logs file, for later resubmission if needed
    cmdadd 'mv condor_trees_submission_temp'
    cmdadd '${condorlogs}/condor_trees_submission_${jobID};'

    # End loop
    cmdadd 'done'

    # Report number of jobs again
    cmd+=('echo Sent ${noJobs} jobs to condor.;')
}

# hadd files on eos
haddFiles(){
    # Merge root files
    echo 'Merge root files.'
    while read outfile; do
        rootfile="${outfile}"/treeProducerSusySingleLepton/tree.root
        fullpath="${eos}${eoschunk}/${rootfile}"
        # Check for new sample
        if [[ "${outfile##*_}" -eq 0 ]]; then
            targetdir="${eosout}"/"${outfile%_*}"/treeProducerSusySingleLepton
            target="${targetdir}"/tree.root
            xrdfs "${eos}" mkdir -p "${targetdir}"
            cmd+=("hadd -f ${eos}${target} ${fullpath}")
        else
            cmdadd "${fullpath}"
        fi
    done < ${outfiles}
    invokeCmd

    # Merge text files
    echo -n 'Download pickle files... '
    while read outfile; do
        pckfile="${outfile}"/skimAnalyzerCount/SkimReport.txt
        fullpath="${eos}"/"${eoschunk}"/"${pckfile}"
        tmpout=tmp/"${out}"/"${outfile%_*}"
        mkdir -p "${tmpout}"
        xrdcp -fs "${fullpath}" "${tmpout}"/"${outfile}".txt
    done < ${outfiles}
    echo 'Done.'

    echo -n 'Merge pickle files... '
    for folder in tmp/"${out}"/*; do
        sample="${folder##*/}"
        # Merge numbers
        awk '
            /All Events/ { all_events+=$3 }
            /Sum Weights/ { sum_weights+=$3 }
            END { print("Counter Skim Report:\n\tAll Events", all_events,
            "\n\tSum Weights", sum_weights) } ' "${folder}"/* \
            > "${out}"/SkimReport_"${sample}".txt

        # Upload to EOS
        eospckfolder="${eosout}"/"${sample}"/skimAnalyzerCount
        xrdfs "${eos}" mkdir -p "${eospckfolder}"
        xrdcp -fs "${out}"/SkimReport_"${sample}".txt "${eos}${eospckfolder}"/SkimReport.txt

    done
    # Delete temporary files
    rm -rf tmp/"${out}"
    echo 'Done.'
}

# Append to last cmd entry
cmdadd(){
    cmd[${#cmd[@]}-1]+=" $1"
}

# Invoke cmd command
invokeCmd(){
    # Invoke command(s) in subshell
    (
        for c in "${cmd[@]}"; do
            echo "$c" >> "${log}"
            eval "$c"
        done
    )
}

main(){
    parseOptions "$@"
    # If hadd is true, we only hadd and ignore all other options
    if [ "${hadd}" == true ]; then
        haddFiles
    else
        produceTrees
    fi
}

main "$@"
